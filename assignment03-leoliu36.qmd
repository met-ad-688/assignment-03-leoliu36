---
title: Assignment 03
author:
  - name: Leo Liu
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-9-23'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
date-modified: today
date-format: long
execute:
  echo: false
  eval: false
  freeze: auto
---

# Loading the Dataset
```{python}
# Data Loading & Setup
import pandas as pd
import plotly.express as px
import plotly.io as pio
from pyspark.sql import SparkSession
import re
import numpy as np
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when, trim
from pyspark.sql import functions as F
from pyspark.sql.functions import col, monotonically_increasing_id

np.random.seed(42)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("../data/lightcast_job_postings.csv")
df.createOrReplaceTempView("job_postings")

# Show Schema and Sample Data
#print("---This is Diagnostic check, No need to print it in the final doc---")
df.printSchema() # comment this line when rendering the submission
df.show(5)
```

# Data Cleaning
```{python}
# Data Cleaning 
## ensure columns are numeric type for computing medians
df = df.withColumn("SALARY_FROM", col("SALARY_FROM").cast("double")). withColumn("SALARY_TO", col("SALARY_TO").cast("double")).withColumn("SALARY", col("SALARY").cast("double")).withColumn("MIN_YEARS_EXPERIENCE", col("MIN_YEARS_EXPERIENCE").cast("double")).withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("double"))

## calculate median salary values
median_from = df.approxQuantile("SALARY_FROM", [0.5], 0.01)[0]
median_to = df.approxQuantile("SALARY_TO", [0.5], 0.01)[0]
median_salary = df.approxQuantile("SALARY", [0.5], 0.01)[0]
average_salary = (median_from + median_to)/2

## print calculated values
print("Median SALARY_FROM:", median_from)
print("Median SALARY_TO:", median_to)
print("Median SALARY:", median_salary)
print("Imputed AVERAGE_SALARY:", average_salary)

## Impute Missing Salary values
df = df.withColumn("SALARY_FROM", F.when(col("SALARY_FROM").isNull(), median_from).otherwise(col("SALARY_FROM"))).withColumn("SALARY_TO", F.when(col("SALARY_TO").isNull(), median_to).otherwise(col("SALARY_TO"))).withColumn("SALARY", F.when(col("SALARY").isNull(), median_to).otherwise(col("SALARY"))).withColumn("Average_Salary", ((col("SALARY_FROM") + col("SALARY_TO"))/2).cast("double"))
#df.select([F.count(F.when(F.col("SALARY").isNull(), True)).alias("Missing_SALARY")]).show()

## Clean categorical columns by removing ", \n, and \r characters 
df = df.withColumn("EMPLOYMENT_TYPE_NAME", trim(F.regexp_replace("EMPLOYMENT_TYPE_NAME", r'[\[\]\\n\\r\"]', ''))).withColumn("LOT_OCCUPATION_NAME", trim(F.regexp_replace("LOT_OCCUPATION_NAME", r'[\[\]\\n\\r\"]', ''))).withColumn("EDUCATION_LEVELS_NAME", trim(F.regexp_replace("EDUCATION_LEVELS_NAME", r'[\[\]\\n\\r\"]', '')))

# Reload the data without complex options
#df = spark.read.option("header", "true").option("inferSchema", "true").csv("../data/lightcast_job_postings.csv")
```

# Exporting Cleaned Data
```{python}
## Export Cleaned Data and re-load the cleaned dataset to continue analysis
df.write.mode("overwrite").csv("cleaned_lightcast.csv/", header=True)
df = spark.read.option("header", "true").option("inferSchema", "true").csv("cleaned_lightcast.csv/")
```

# Salary Distribution by Industry and Employment Type
```{python}
# Filter data to remove records with missing or zero from SALARY_FROM
filtered_df1 = df.filter(
  (col("SALARY_FROM").isNotNull()) & 
  (col("SALARY_FROM") > 0)
  )

# Aggregate data to group by NAICS2_NAME and EMPLOYMENT_TYPE_NAME and include salary distribution
df1 = filtered_df1.select("SALARY_FROM", "NAICS2_NAME", "EMPLOYMENT_TYPE_NAME").toPandas()

# df.select("EMPLOYMENT_TYPE_NAME").distinct().show(truncate=False) verified that EMPLOYMENT_TYPE_NAME field required additional cleaning
# Additional Cleaning on EMPLOYMENT_TYPE_NAME
clean_legend = {
  'Pat-time / full-time': 'Part-time / Full-time',
  'Pat-time (â‰¤ 32 hous)':'Part-time (≤ 32 hours)',
  'Full-time (> 32 hous)':'Full-time (> 32 hours)'
}

# Update df to use cleaned values and remove nulls
df1["EMPLOYMENT_TYPE_NAME"] = (df1["EMPLOYMENT_TYPE_NAME"].replace(clean_legend))
df1=df1[df1["EMPLOYMENT_TYPE_NAME"].notnull()]

## Generate Visualization
# Create Box Plot
fig1 = px.box(
  df1,
  x="NAICS2_NAME",
  y="SALARY_FROM",
  color="EMPLOYMENT_TYPE_NAME",
  title="Salary Distribution by Industry and Employment Type",
)
fig1.update_layout(
    font=dict(family="Helvetica Neue", size=9, color="#333"),
    title_font=dict(size=20, color="#1f77b4"),
    colorway=["#ec7424", "#a4abab"],
    legend_title="Employment Type",
    xaxis_title="Industry",
    yaxis_title="Minimum Salary ($)",
    xaxis_tickangle=60,
    hovermode="x unified",
    width=1400,
    height=800
)
fig1.show()
```

## Salary Analysis by ONET Occupation Type (Bubble Chart)
```{python}
# Filter data to remove nulls and zeros from SALARY_FROM and LOT_OCCUPATION_NAME
filtered_df2 = df.filter(
    (col("SALARY_FROM").isNotNull()) &
    (col("SALARY_FROM") > 0) &
    (col("LOT_OCCUPATION_NAME").isNotNull()) &
    (trim(col("LOT_OCCUPATION_NAME")) != "")
)

# Compute median salary and job count per LOT_OCCUPATION_NAME group
filtered_df2_grouped = filtered_df2.groupBy("LOT_OCCUPATION_NAME").agg(
    F.expr("percentile_approx(SALARY_FROM, 0.5)").alias("Median_Salary"),
    F.count("*").alias("Job_Postings")
)

# Convert to pandas and remove occupations with low job count
df2 = filtered_df2_grouped.toPandas()
df2 = df2[df2["Job_Postings"] > 50]

# Create Bubble Chart
fig2 = px.scatter(
  df2, 
  x="LOT_OCCUPATION_NAME",
  y="Median_Salary",
  size="Job_Postings",
  title="Salary Analysis by LOT Occupation Type",
  color="Median_Salary",
  size_max=100
)
fig2.update_layout(
    font=dict(family="Helvetica Neue", size=9, color="#333"),
    title_font=dict(size=20, color="#1f77b4"),
    colorway=["#ec7424", "#a4abab"],
    xaxis_title="LOT Occupation",
    yaxis_title="Median Salary ($)",
    xaxis_tickangle=45,
    hovermode="closest",
    width=1400,
    height=800
)
fig2.show()
```

# Salary by Education Level
```{python}
# Filter data to remove missing salary and education levels
filtered_df3 = df.filter(
    (col("SALARY_FROM").isNotNull()) &
    (col("SALARY_FROM") > 0) &
    (col("EDUCATION_LEVELS_NAME").isNotNull()) &
    (trim(col("EDUCATION_LEVELS_NAME")) != "")
)

# Group by EDUCATION_LEVELS_NAME and compute Median Salary & Job Count
filtered_df3_grouped = filtered_df3.groupBy("EDUCATION_LEVELS_NAME").agg(
    F.expr("percentile_approx(SALARY_FROM, 0.5)").alias("Median_Salary"),
    F.count("*").alias("Job_Postings")
)

# Convert to pandas for plotting and sort by median salary descending
df3 = filtered_df3_grouped.toPandas()
df3 = df3.sort_values(by="Median_Salary", ascending=True)

# Create horizontal bar chart
fig3 = px.bar(
    df3,
    x="Median_Salary",
    y="EDUCATION_LEVELS_NAME",
    orientation="h",
    text="Median_Salary",
    title="Median Salary by Education Level",
    labels={"EDUCATION_LEVELS_NAME": "Education Level", "Median_Salary": "Median Salary ($)"}
)

fig3.update_layout(
    font=dict(family="Helvetica Neue", size=9, color="#333"),
    title_font=dict(size=20, color="#1f77b4"),
    colorway=["#1f77b4"],
    xaxis_title="Median Salary ($)",
    yaxis_title="Education Level",
    hovermode="y unified",
    width=900,
    height=500
)
fig3.show()
```

# Salary by Education Level
```{python}
# Filter data invalid entries
filtered_df4 = df.filter(
    (col("SALARY_FROM").isNotNull()) &
    (col("SALARY_FROM") > 0) &
    (col("REMOTE_TYPE_NAME").isNotNull()) &
    (trim(col("REMOTE_TYPE_NAME")) != "")
)

# Group by Remote Work Type and calculate Median Salary & Job Count
filtered_df4_grouped = filtered_df4.groupBy("REMOTE_TYPE_NAME").agg(
    F.expr("percentile_approx(SALARY_FROM, 0.5)").alias("Median_Salary"),
    F.count("*").alias("Job_Postings")
)

# Convert to pandas
df4 = filtered_df4_grouped.toPandas()
df4 = df4.sort_values(by="Median_Salary", ascending=True)

# Create horizontal bar chart
fig4 = px.bar(
    df4,
    x="Median_Salary",
    y="REMOTE_TYPE_NAME",
    orientation="h",
    text="Median_Salary",
    title="Median Salary by Remote Work Type",
    labels={"REMOTE_TYPE_NAME": "Remote Work Type", "Median_Salary": "Median Salary ($)"}
)

fig4.update_layout(
    font=dict(family="Helvetica Neue", size=9, color="#333"),
    title_font=dict(size=20, color="#1f77b4"),
    xaxis_title="Median Salary ($)",
    yaxis_title="Remote Work Type",
    hovermode="y unified",
    width=900,
    height=500
)
fig4.show()
```